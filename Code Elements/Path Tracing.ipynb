{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "627c21a0-1e27-43b1-9426-221294771829",
   "metadata": {},
   "source": [
    "# Path Tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de187874-2cf3-43f4-9268-73cf75333f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# pip install Pillow\n",
    "    # open Anaconda Prompt and paste above line (without '#') to install package\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b487a60-f366-4bdf-9917-7e3fb957551e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gives a range on hues given a color\n",
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerLimit = hsvC[0][0][0] - 10, 100, 100\n",
    "    upperLimit = hsvC[0][0][0] + 10, 255, 255\n",
    "    # the +/-10 defines the range of hues that fall within the limits (the h in hsv)\n",
    "    # the range on saturation and value is much bigger because we are only looking for hue\n",
    "    \n",
    "    lowerLimit = np.array(lowerLimit, dtype=np.uint8)\n",
    "    upperLimit = np.array(upperLimit, dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c527ce0e-4012-449d-8ed7-60cc52f2c426",
   "metadata": {},
   "outputs": [],
   "source": [
    "color = [194, 137, 50]     # color to detect (in BGR colorspace)\n",
    "line_color = color     # color used to draw path\n",
    "line_thickness = 5     # line thickness\n",
    "capture = cv2.VideoCapture(0)     # picks camera to use (usually 0 or 1)\n",
    "\n",
    "if (line_color == [0, 0, 0]): # breaks if you use black ([0, 0, 0]), so we adjust it\n",
    "    line_color = [1, 1, 1]\n",
    "\n",
    "first = False\n",
    "path = 0\n",
    "h = 0\n",
    "w = 0\n",
    "points = list() # array that will hold locations of detected colors\n",
    "pointsPrev = list() # array that will hold the locations of detected colors from the previous frame\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    if (first == False): # runs only once\n",
    "        # get height and width of video\n",
    "        shape = frame.shape \n",
    "        h = shape[0]\n",
    "        w = shape[1]\n",
    "        # create path image to draw on (based on shape of webcam feed)\n",
    "        path = np.array(Image.new(\"RGB\", (w, h), (0,0,0)))\n",
    "        # set first to True so this block doesn't run again\n",
    "        first = True\n",
    "    \n",
    "    frame_blur = cv2.GaussianBlur(frame, (11, 11), 17) # blurring the image may help get the desired result, but it can be removed\n",
    "    \n",
    "    frame_hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV) # convert to HSV\n",
    "    lowerLimit, upperLimit = get_limits(color) # range of hues that we want the software to detect\n",
    "    \n",
    "    # define points and prevPoints to decide where to draw lines (changes every frame)\n",
    "    pointsPrev = points \n",
    "    points = list() # empty the array to add new points\n",
    "\n",
    "    # draw bounding boxes\n",
    "    mask = cv2.inRange(frame_hsv, lowerLimit, upperLimit) # detects objects in color range\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = list()\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > 100:  # only continues if size of the object is large enough (removes noise)\n",
    "            x1, y1, w, h = cv2.boundingRect(cnt) # finds a bounding box for each object\n",
    "            c = list([int(x1 + w/2), int(y1 + h/2)])  # centerpoint of bbox\n",
    "            # check other bboxes to see if we want to combine them into 1 box\n",
    "            newBox = list([c[0], c[1], x1, y1, w, h])\n",
    "            for i in bboxes[:]:\n",
    "                cxi, cyi, x1i, y1i, wi, hi = i  # bbox we check the newBox against\n",
    "                if np.sqrt((c[0] - cxi)**2 + (c[1] - cyi)**2) < np.sqrt(w**2 + h**2)/3 + np.sqrt(wi**2 + hi**2)/3 + 25: # if centerpoints are close enough (scales with box size)\n",
    "                    bboxes.remove(i)\n",
    "                    # reassign bbox boundaries so the new box contains both nearby boxes\n",
    "                    newBox[2], newBox[3] = min(x1, x1i), min(y1, y1i)  # reassigns x1 and y1 values\n",
    "                    newBox[4], newBox[5] = max(x1+w, x1i+wi) - newBox[2], max(y1+h, y1i+hi) - newBox[3]  # reassgins w and h values\n",
    "                    newBox[0], newBox[1] = int(newBox[2] + newBox[4]/2), int(newBox[3] + newBox[5]/2)  # reassigns centerpoint values\n",
    "            bboxes.append(newBox)\n",
    "    \n",
    "    for i in bboxes:  # draws bboxes after we have curated the list\n",
    "        cx, cy, x1, y1, w, h = i\n",
    "        cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
    "        # take a point from the bounding box and add it to \"points\" list (for each bbox)\n",
    "        points.append([int(x1 + 0.5*w), int(y1 + 0.5*h)]) # uses center point of bbox\n",
    "        # points.append([int(x1 + 0.5*w), y1]) # uses bottom-center point of bbox (alternative to above line)\n",
    "            # need to cast int() because you can't have half a frame\n",
    "\n",
    "    # draw lines between an object's old and new positions\n",
    "        # compares all points from \"points\" and \"prevPoints\"\n",
    "    for i in pointsPrev:\n",
    "        for j in points:\n",
    "            if ( np.sqrt( (i[0] - j[0])**2 + (i[1] - j[1])**2 ) < 50 ):     # will draw a line only if two points are close enough        \n",
    "                cv2.line(path, (i[0], i[1]), (j[0], j[1]), line_color, line_thickness)\n",
    "\n",
    "                break  # break so two lines don't get drawn from the same point\n",
    "\n",
    "    # overlay the path over the webcam feed\n",
    "    mask2 = cv2.cvtColor(path, cv2.COLOR_BGR2GRAY)\n",
    "    mask2 = cv2.threshold(mask2, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    mask2inv = cv2.bitwise_not(mask2)\n",
    "    pathfg = cv2.bitwise_and(path, path, mask=mask2) # extract foreground\n",
    "    framebg = cv2.bitwise_and(frame, frame, mask=mask2inv) # extract background\n",
    "    frame = cv2.add(framebg, pathfg) # combine foreground and background\n",
    "\n",
    "    # display videos\n",
    "    cv2.imshow('blur', frame_blur)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('path', path)\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    if key == 32:               # 32 is ASCE for [spacebar]\n",
    "        break                   # ends loop when spacebar is pressed\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()  # closes window, only reaches here when spacebar is pressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a1667-3d49-424d-81e2-38fad38663de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
