{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113e12c2-a9be-4639-8584-4a1fe2118a47",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "### Supply Chain Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d70acbc1-bc66-450d-b221-cea28aa1b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# pip install Pillow\n",
    "    # open Anaconda Prompt and paste above line (without '#') to install package\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7240f9e8-61b0-4881-a3d0-b11c710a3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gives a range on hues given a color\n",
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerLimit = hsvC[0][0][0] - 10, 100, 100\n",
    "    upperLimit = hsvC[0][0][0] + 10, 255, 255\n",
    "    # the +/-10 defines the range of hues that fall within the limits (the h in hsv)\n",
    "    # the range on saturation and value is much bigger because we are only looking for hue\n",
    "    \n",
    "    lowerLimit = np.array(lowerLimit, dtype=np.uint8)\n",
    "    upperLimit = np.array(upperLimit, dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c1bdb51-67c2-4ab9-98e0-2141f1878c7b",
   "metadata": {},
   "source": [
    "How to use:\n",
    "- place color marker on the node indicated on screen\n",
    "- press [spacebar] to record that point\n",
    "  - press [backspace] to undo\n",
    "- once you have recorded all points, program ends and prints the points\n",
    "- copy and paste the output into the \"points\" variable on the main Supply Chain Maze program\n",
    "\n",
    "The points you find on this program will tell us the location of the nodes in the main SCM program, so that we can look around those points for markers and draw lines between nodes.\n",
    "If you move the camera after using this program, the points will be inaccurate and you will need to recalibrate.\n",
    "There are 9 points being recorded, start, end, and numbers 1-7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "809faeb7-6c88-4ff1-9d96-df1d6298c850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[99, 235], [192, 142], [172, 322], [301, 114], [281, 221], [283, 342], [436, 106], [442, 326], [539, 210]]\n"
     ]
    }
   ],
   "source": [
    "color = [90, 144, 31]  # color in BGR colorspace\n",
    "detection_size = 100              # size of detection required to mark color as an object\n",
    "capture = cv2.VideoCapture(0)     # picks camera to use (usually 0 or 1)\n",
    "\n",
    "first = False\n",
    "height = 0\n",
    "count = 0\n",
    "nodes = list()\n",
    "key = 0\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    if (first == False):\n",
    "        shape = frame.shape\n",
    "        height = shape[0]\n",
    "        width = shape[1]\n",
    "        cqm = width / 640  # scales detection with video quality (because it depends on number of pixels)\n",
    "        first = True\n",
    "    \n",
    "    frame_blur = cv2.GaussianBlur(frame, (11, 11), 9) # blurring the image may help get the desired result, but it can be removed\n",
    "    \n",
    "    frame_hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV) # convert to HSV\n",
    "    lowerLimit, upperLimit = get_limits(color) # range of hues that we want the software to detect\n",
    "    \n",
    "    mask = cv2.inRange(frame_hsv, lowerLimit, upperLimit) # detects objects in color range\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = list()\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > detection_size*cqm**2:  # only continues if size of the object is large enough (removes noise)\n",
    "            x1, y1, w, h = cv2.boundingRect(cnt) # finds a bounding box for each object\n",
    "            c = list([int(x1 + w/2), int(y1 + h/2)])  # centerpoint of bbox\n",
    "            # check other bboxes to see if we want to combine them into 1 box\n",
    "            newBox = list([c[0], c[1], x1, y1, w, h, cv2.contourArea(cnt)])\n",
    "            for i in bboxes[:]:\n",
    "                cxi, cyi, x1i, y1i, wi, hi, si = i  # bbox we check the newBox against\n",
    "                if np.sqrt((c[0] - cxi)**2 + (c[1] - cyi)**2) < np.sqrt(w**2 + h**2)/3 + np.sqrt(wi**2 + hi**2)/3 + cqm*30: # if centerpoints are close enough (scales with box size)\n",
    "                    bboxes.remove(i)\n",
    "                    # reassign bbox boundaries so the new box contains both nearby boxes\n",
    "                    newBox[2], newBox[3] = min(x1, x1i), min(y1, y1i)  # reassigns x1 and y1 values\n",
    "                    newBox[4], newBox[5] = max(x1+w, x1i+wi) - newBox[2], max(y1+h, y1i+hi) - newBox[3]  # reassgins w and h values\n",
    "                    newBox[0], newBox[1] = int(newBox[2] + newBox[4]/2), int(newBox[3] + newBox[5]/2)  # reassigns centerpoint values\n",
    "            bboxes.append(newBox)\n",
    "\n",
    "    # find the largest object\n",
    "    maxVal = 0\n",
    "    point = 0\n",
    "    for i in bboxes:  \n",
    "        cx, cy, x1, y1, w, h, s = i\n",
    "        if s > maxVal:\n",
    "            maxVal = s\n",
    "            point = i\n",
    "\n",
    "    # draw bounding box\n",
    "    if point != 0:\n",
    "        cx, cy, x1, y1, w, h, s = point\n",
    "        cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
    "        # drawing dots at the centerpoint\n",
    "        cv2.line(frame, (cx, cy), (cx, cy), (255, 0, 0), 15)\n",
    "        cv2.line(frame, (cx, cy), (cx, cy), (0, 255, 255), 10)\n",
    "        cv2.line(frame, (cx, cy), (cx, cy), (0, 0, 255), 5)\n",
    "\n",
    "    # print instruction text\n",
    "    text_color = (0, 0, 0)\n",
    "    text_border_color = (255, 255, 255)\n",
    "    if count == 0:\n",
    "        cv2.putText(frame, 'Calibrating: Start', (int(24*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: Start', (int(26*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: Start', (int(25*cqm), int(height - 24*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: Start', (int(25*cqm), int(height - 26*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: Start', (int(25*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_color, int(1*cqm))\n",
    "    elif count == 8:\n",
    "        cv2.putText(frame, 'Calibrating: End', (int(24*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: End', (int(26*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: End', (int(25*cqm), int(height - 24*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: End', (int(25*cqm), int(height - 26*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, 'Calibrating: End', (int(25*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_color, int(1*cqm))\n",
    "    else:\n",
    "        cv2.putText(frame, f'Calibrating: Point {count}', (int(24*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, f'Calibrating: Point {count}', (int(26*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, f'Calibrating: Point {count}', (int(25*cqm), int(height - 24*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, f'Calibrating: Point {count}', (int(25*cqm), int(height - 26*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_border_color, int(1*cqm))\n",
    "        cv2.putText(frame, f'Calibrating: Point {count}', (int(25*cqm), int(height - 25*cqm)), cv2.FONT_HERSHEY_TRIPLEX, int(1*cqm), text_color, int(1*cqm))\n",
    "    \n",
    "    \n",
    "    # record locations of nodes\n",
    "    if key == 32 and point != 0:   # when [spacebar] is pressed\n",
    "        nodes.append([point[0], point[1]])\n",
    "        point = 0\n",
    "        maxVal = 0\n",
    "        count += 1\n",
    "        if count >= 9:\n",
    "            break\n",
    "        cv2.waitKey(250)    \n",
    "\n",
    "    # removes last point if [backspace] is pressed\n",
    "    if key == 8 and len(nodes) > 0:\n",
    "        nodes.pop()\n",
    "        count -= 1\n",
    "        cv2.waitKey(250)\n",
    "                 \n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    if key == 27:               # 27 is ASCII for [ESC]\n",
    "        break                   # ends loop when [ESC] is pressed\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()  # closes window, only reaches here when spacebar is pressed\n",
    "\n",
    "# print points we found\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837da07-ac65-41b0-a521-c3686ac78f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
