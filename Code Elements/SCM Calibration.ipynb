{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "113e12c2-a9be-4639-8584-4a1fe2118a47",
   "metadata": {},
   "source": [
    "# Calibration\n",
    "### Supply Chain Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d70acbc1-bc66-450d-b221-cea28aa1b2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# pip install Pillow\n",
    "    # open Anaconda Prompt and paste above line (without '#') to install package\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7240f9e8-61b0-4881-a3d0-b11c710a3557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gives a range on hues given a color\n",
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerLimit = hsvC[0][0][0] - 10, 100, 100\n",
    "    upperLimit = hsvC[0][0][0] + 10, 255, 255\n",
    "    # the +/-10 defines the range of hues that fall within the limits (the h in hsv)\n",
    "    # the range on saturation and value is much bigger because we are only looking for hue\n",
    "    \n",
    "    lowerLimit = np.array(lowerLimit, dtype=np.uint8)\n",
    "    upperLimit = np.array(upperLimit, dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "809faeb7-6c88-4ff1-9d96-df1d6298c850",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222, 207], [237, 224], [243, 228], [251, 232], [257, 234], [256, 234], [257, 235], [258, 235], [257, 234]]\n"
     ]
    }
   ],
   "source": [
    "color = [194, 137, 50]  # color in BGR colorspace\n",
    "detection_size = 500              # size of detection required to mark color as an object\n",
    "capture = cv2.VideoCapture(0)     # picks camera to use (usually 0 or 1)\n",
    "\n",
    "first = False\n",
    "height = 0\n",
    "count = 0\n",
    "nodes = list()\n",
    "key = 0\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    if (first == False):\n",
    "        shape = frame.shape\n",
    "        height = shape[0]\n",
    "        width = shape[1]\n",
    "        camera_quality_mod = width / 640  # scales detection with video quality (because it depends on number of pixels)\n",
    "        first = True\n",
    "    \n",
    "    frame_blur = cv2.GaussianBlur(frame, (11, 11), 9) # blurring the image may help get the desired result, but it can be removed\n",
    "    \n",
    "    frame_hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV) # convert to HSV\n",
    "    lowerLimit, upperLimit = get_limits(color) # range of hues that we want the software to detect\n",
    "    \n",
    "    mask = cv2.inRange(frame_hsv, lowerLimit, upperLimit) # detects objects in color range\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = list()\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > detection_size*camera_quality_mod**2:  # only continues if size of the object is large enough (removes noise)\n",
    "            x1, y1, w, h = cv2.boundingRect(cnt) # finds a bounding box for each object\n",
    "            c = list([int(x1 + w/2), int(y1 + h/2)])  # centerpoint of bbox\n",
    "            # check other bboxes to see if we want to combine them into 1 box\n",
    "            newBox = list([c[0], c[1], x1, y1, w, h, cv2.contourArea(cnt)])\n",
    "            for i in bboxes[:]:\n",
    "                cxi, cyi, x1i, y1i, wi, hi, si = i  # bbox we check the newBox against\n",
    "                if np.sqrt((c[0] - cxi)**2 + (c[1] - cyi)**2) < np.sqrt(w**2 + h**2)/3 + np.sqrt(wi**2 + hi**2)/3 + camera_quality_mod*30: # if centerpoints are close enough (scales with box size)\n",
    "                    bboxes.remove(i)\n",
    "                    # reassign bbox boundaries so the new box contains both nearby boxes\n",
    "                    newBox[2], newBox[3] = min(x1, x1i), min(y1, y1i)  # reassigns x1 and y1 values\n",
    "                    newBox[4], newBox[5] = max(x1+w, x1i+wi) - newBox[2], max(y1+h, y1i+hi) - newBox[3]  # reassgins w and h values\n",
    "                    newBox[0], newBox[1] = int(newBox[2] + newBox[4]/2), int(newBox[3] + newBox[5]/2)  # reassigns centerpoint values\n",
    "            bboxes.append(newBox)\n",
    "\n",
    "    # find the largest object\n",
    "    maxVal = 0\n",
    "    point = 0\n",
    "    for i in bboxes:  \n",
    "        cx, cy, x1, y1, w, h, s = i\n",
    "        if s > maxVal:\n",
    "            maxVal = s\n",
    "            point = i\n",
    "\n",
    "    if point != 0:\n",
    "        cx, cy, x1, y1, w, h, s = point\n",
    "        cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
    "        cv2.line(frame, (cx, cy), (cx, cy), (255, 0, 0), 15)\n",
    "        cv2.line(frame, (cx, cy), (cx, cy), (0, 255, 255), 10)\n",
    "        cv2.line(frame, (cx, cy), (cx, cy), (0, 0, 255), 5)\n",
    "\n",
    "    # print instruction text\n",
    "    if count == 0:\n",
    "        cv2.putText(frame, 'Calibrating: Start', (25, height - 25), cv2.FONT_HERSHEY_TRIPLEX, 1, (150, 150, 150), 1)\n",
    "    elif count == 8:\n",
    "        cv2.putText(frame, 'Calibrating: End', (25, height - 25), cv2.FONT_HERSHEY_TRIPLEX, 1, (150, 150, 150), 1)\n",
    "    else:\n",
    "        cv2.putText(frame, f'Calibrating: Point {count}', (25, height - 25), cv2.FONT_HERSHEY_TRIPLEX, 1, (150, 150, 150), 1)\n",
    "    \n",
    "    \n",
    "    # record locations of nodes\n",
    "    if key == 32 and point != 0:   # when [spacebar] is pressed\n",
    "        nodes.append([point[0], point[1]])\n",
    "        point = 0\n",
    "        maxVal = 0\n",
    "        count += 1\n",
    "        if count >= 9:\n",
    "            break\n",
    "        cv2.waitKey(250)    \n",
    "                 \n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    if key == 27:               # 27 is ASCE for [ESC]\n",
    "        break                   # ends loop when [ESC] is pressed\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()  # closes window, only reaches here when spacebar is pressed\n",
    "\n",
    "# print points we found\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1837da07-ac65-41b0-a521-c3686ac78f3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
