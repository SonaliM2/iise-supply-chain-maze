{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c2892a-4c22-4281-b810-8b38c5f74b61",
   "metadata": {},
   "source": [
    "# Supply Chain Maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f900a801-261e-4c6e-8853-1d7a0c2e780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# pip install Pillow\n",
    "    # open Anaconda Prompt and paste above line (without '#') to install package\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63ca1c8c-77f2-4aec-ae03-d9dba6228c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gives a range on hues given a color\n",
    "def get_limits(color):\n",
    "    c = np.uint8([[color]])\n",
    "    hsvC = cv2.cvtColor(c, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    lowerLimit = hsvC[0][0][0] - 10, 100, 100\n",
    "    upperLimit = hsvC[0][0][0] + 10, 255, 255\n",
    "    # the +/-10 defines the range of hues that fall within the limits (the h in hsv)\n",
    "    # the range on saturation and value is much bigger because we are only looking for hue\n",
    "    \n",
    "    lowerLimit = np.array(lowerLimit, dtype=np.uint8)\n",
    "    upperLimit = np.array(upperLimit, dtype=np.uint8)\n",
    "\n",
    "    return lowerLimit, upperLimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d190fc28-8395-4eff-928c-567bbf738d52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n"
     ]
    }
   ],
   "source": [
    "# take from SCM Calibration\n",
    "points = [[325, 45], [172, 146], [478, 153], [191, 228], [357, 232], [481, 237], [211, 332], [451, 328], [336, 417]]\n",
    "\n",
    "color = [255, 0, 0]                 # color in BGR colorspace\n",
    "line_color = [168, 45, 81]            # color used to draw path\n",
    "line_size = 3                         # line thickness\n",
    "line_color_check = [0, 255, 255]      # line color used to draw the correct solution\n",
    "detection_size = 500                  # size of detection required to mark color as an object\n",
    "capture = cv2.VideoCapture(0)         # picks camera to use (usually 0 or 1)\n",
    "\n",
    "if (line_color == [0, 0, 0]): # breaks if you use black ([0, 0, 0]), so we adjust it\n",
    "    line_color = [1, 1, 1]\n",
    "if (line_color_check == [0, 0, 0]): # breaks if you use black ([0, 0, 0]), so we adjust it\n",
    "    line_color_check = [1, 1, 1]\n",
    "\n",
    "first = False\n",
    "count = 0\n",
    "prev_node = -1\n",
    "current_node = -1\n",
    "path_value = 0\n",
    "                     # node   s   1   2   3   4   5   6   7   e\n",
    "adjacency_matrix = np.array([[0,  4,  8,  0,  0,  0,  0,  0,  0 ],   # start\n",
    "                             [4,  0,  11, 4,  0,  0,  0,  0,  0 ],   # 1\n",
    "                             [8,  11, 0,  0,  2,  7,  0,  0,  0 ],   # 2\n",
    "                             [0,  4,  0,  0,  1,  0,  7,  7,  0 ],   # 3\n",
    "                             [0,  0,  2,  1,  0,  4,  0,  0,  0 ],   # 4\n",
    "                             [0,  0,  7,  0,  4,  0,  0,  7,  0 ],   # 5\n",
    "                             [0,  0,  0,  7,  0,  0,  0,  11, 8 ],   # 6\n",
    "                             [0,  0,  0,  7,  0,  7,  11, 0,  11],   # 7\n",
    "                             [0,  0,  0,  0,  0,  0,  8,  11, 0 ]])  # end\n",
    "                # a '1' indicates that two nodes (corresponing to the row and column) are adjacent\n",
    "                # the matrix is symmetric, so it doesn't matter if you take [3][4] or [4][3] ; they tell you the same thing\n",
    "while True:\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    \n",
    "    if (first == False): # runs only once\n",
    "        # get height and width of video\n",
    "        shape = frame.shape\n",
    "        height = shape[0]\n",
    "        width = shape[1]\n",
    "        camera_quality_mod = width / 640  # scales detection with video quality (because it depends on number of pixels)\n",
    "        line_thickness = int(line_size * camera_quality_mod)\n",
    "        # create path image to draw on (based on shape of webcam feed)\n",
    "        path = np.array(Image.new(\"RGB\", (width, height), (0,0,0)))\n",
    "        # draw dots to mark each node at each node\n",
    "        for i in points:\n",
    "            cv2.circle(path, i, 1, (0, 255, 255), int(5*camera_quality_mod))\n",
    "        # set first to True so this block doesn't run again\n",
    "        first = True\n",
    "\n",
    "    frame_blur = cv2.GaussianBlur(frame, (11, 11), 9) # blurring the image may help get the desired result, but it can be removed\n",
    "    \n",
    "    frame_hsv = cv2.cvtColor(frame_blur, cv2.COLOR_BGR2HSV) # convert to HSV\n",
    "    lowerLimit, upperLimit = get_limits(color) # range of hues that we want the software to detect\n",
    "    \n",
    "    mask = cv2.inRange(frame_hsv, lowerLimit, upperLimit) # detects objects in color range\n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = list()\n",
    "    for cnt in contours:\n",
    "        if cv2.contourArea(cnt) > camera_quality_mod*detection_size:  # only continues if size of the object is large enough (removes noise)\n",
    "            x1, y1, w, h = cv2.boundingRect(cnt)  # finds a bounding box for each object\n",
    "            c = list([int(x1 + w/2), int(y1 + h/2)])  # centerpoint of bbox\n",
    "            # check other bboxes to see if we want to combine them into 1 box\n",
    "            newBox = list([c[0], c[1], x1, y1, w, h, cv2.contourArea(cnt)])\n",
    "            for i in bboxes[:]:\n",
    "                cxi, cyi, x1i, y1i, wi, hi, si = i  # bbox we check the newBox against\n",
    "                if np.sqrt((c[0] - cxi)**2 + (c[1] - cyi)**2) < np.sqrt(w**2 + h**2)/3 + np.sqrt(wi**2 + hi**2)/3 + camera_quality_mod*25: # if centerpoints are close enough (scales with box size)\n",
    "                    bboxes.remove(i)\n",
    "                    # reassign bbox boundaries so the new box contains both nearby boxes\n",
    "                    newBox[2], newBox[3] = min(x1, x1i), min(y1, y1i)  # reassigns x1 and y1 values\n",
    "                    newBox[4], newBox[5] = max(x1+w, x1i+wi) - newBox[2], max(y1+h, y1i+hi) - newBox[3]  # reassgins w and h values\n",
    "                    newBox[0], newBox[1] = int(newBox[2] + newBox[4]/2), int(newBox[3] + newBox[5]/2)  # reassigns centerpoint values\n",
    "            bboxes.append(newBox)\n",
    "\n",
    "    # overlay the path over the webcam feed\n",
    "    mask2 = cv2.cvtColor(path, cv2.COLOR_BGR2GRAY)\n",
    "    mask2 = cv2.threshold(mask2, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "    mask2inv = cv2.bitwise_not(mask2)\n",
    "    pathfg = cv2.bitwise_and(path, path, mask=mask2) # extract foreground\n",
    "    framebg = cv2.bitwise_and(frame, frame, mask=mask2inv) # extract background\n",
    "    frame = cv2.add(framebg, pathfg) # combine foreground and background\n",
    "    \n",
    "    # find the largest object\n",
    "    maxVal = 0\n",
    "    point = 0\n",
    "    for i in bboxes:  \n",
    "        cx, cy, x1, y1, w, h, s = i\n",
    "        if s > maxVal:\n",
    "            maxVal = s\n",
    "            point = i\n",
    "\n",
    "    # draw circle around current node\n",
    "    if current_node != -1:\n",
    "        cv2.circle(frame, points[current_node], int(20*camera_quality_mod), (0, 0, 255), int(3*camera_quality_mod))\n",
    "        \n",
    "    # draw bounding box\n",
    "    if point != 0:\n",
    "        cx, cy, x1, y1, w, h, s = point\n",
    "        cv2.rectangle(frame, (x1, y1), (x1 + w, y1 + h), (0, 0, 255), 2)\n",
    "\n",
    "        # check if we are close enough to a node\n",
    "        for index, value in enumerate(points):\n",
    "            if current_node == -1 and index == 0 and (point[0]-value[0])**2+(point[1]-value[1])**2 < camera_quality_mod*200:\n",
    "                current_node = 0\n",
    "            if adjacency_matrix[current_node][index] != 0 and index != prev_node and (point[0]-value[0])**2+(point[1]-value[1])**2 < camera_quality_mod*50:\n",
    "                cv2.line(path, (points[current_node][0], points[current_node][1]), (points[index][0], points[index][1]), (0, 255, 255), line_thickness)\n",
    "                prev_node = current_node\n",
    "                current_node = index\n",
    "                path_value += adjacency_matrix[prev_node][current_node]\n",
    "\n",
    "    \n",
    "    cv2.imshow('blur', frame_blur)\n",
    "    cv2.imshow('mask', mask)\n",
    "    cv2.imshow('webcam', frame)\n",
    "\n",
    "    key = cv2.waitKey(10) & 0xFF\n",
    "    if key == 27:               # 27 is ASCE for [ESC]\n",
    "        break                   # ends loop when [ESC] is pressed\n",
    "\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()  # closes window, only reaches here when spacebar is pressed\n",
    "\n",
    "print(path_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b852bc77-0bf8-42a9-8d04-75f1954ab3b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
